{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i6540nXPVnry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Prueba Final del Proyecto: Predicción de Obesidad a partir de Hábitos de Vida\n",
        "\n",
        "El objetivo del proyecto es aplicar técnicas de aprendizaje no supervisado para realizar una agrupación, asociación y reducción de dimensionalidad de los datos, con el fin de descubrir patrones y estructuras ocultas sin el uso de etiquetas (como la variable \"NObeyesdad\"), y adicional, no utilizar las variables de peso y altura para encontrar patrones que nos permitan identificar que otras variables permiten determinar el IMC y el nivel de obesidad de la persona. En un segundo momento utilizaremos aprendizaje supervisado para entrenar nuevamente el modelo, para evaluar la eficiencia y confiabilidad del modelo.\n",
        "\n",
        "## Tabla de Contenidos\n",
        "- [Descripción](#descripción)\n",
        "- [Estructura del proyecto](#Estructura)\n",
        "- [Tecnologías utilizadas](#tecnologías-utilizadas)\n",
        "- [Instalación y despliegue](#instalación)\n",
        "- [Integrantes](#Integrantes)\n",
        "\n",
        "## Descripción\n",
        "\n",
        "Este proyecto es una aplicación que demuestra cómo funcionan y se aplican dos conceptos clave dentro de Machine Learning, Aprendizaje Supervisado y No supervisado para determinar el nivel de obesidad de una persona a partir de los datos suministrados y aplicando diferentes técnicas/metodologías como: (Reducción de dimensionalidad, definición de clústeres, evaluación de las variables, selección de modelo, reentrenamiento y visualización).\n",
        "Algunas de las bibliotecas/librerias que se utilizaron fueron:\n",
        "- Pandas  \n",
        "- numpy  \n",
        "- matplotlib  \n",
        "- seaborn  \n",
        "- sklearn  \n",
        "- xgboost  \n",
        "- shap\n",
        "\n",
        "## Estructura del proyecto\n",
        "### 1. **Cuadernos/**\n",
        "La carpeta contiene el notebook que se utilizo para la realización del ejercicio, en el se encuentra los experimentos, análisis de datos, visualizaciones y desarrollo de los modelos descritos en el proyecto.\n",
        "### 2. **Datos/**\n",
        "En esta carpeta se podrá encontrar los datos del repositorio de ML, el cual se utilizo para en análisis respectivo.\n",
        "### 3. **Documentacion/**\n",
        "Contiene información adicional sobre el proyecto, brindando una información mas técnica y descripción de las metodologías aplicadas.\n",
        "### 4. **README/**\n",
        "Archivo que contiene una información mas general del proyecto, el cual explica de manera concisa como esta construido el proyecto y como realizar el respectivo despliegue\n",
        "### 5. **pyproject.toml/**\n",
        "Archivo de configuración para proyectos de python, su función es especificar las dependencias y configuraciones con las cuales se realizo el despliegue del proyecto.\n",
        "\n",
        "## Tecnologías utilizadas\n",
        "- **Python**: Versión 3.11.\n",
        "- **Poetry**: Gestión de dependencias.\n",
        "- **Pandas**: Manipulación de datos .\n",
        "- **Numpy**: Operaciones matemáticas dentro de los datos.\n",
        "- **matplotlib**: Visualización de datos.\n",
        "- **seaborn**: Visualización de relaciones estadísticas entre variables.\n",
        "- **sklearn**: Creacion y evaluacion de modelos de ML para entrenar modelos.\n",
        "- **xgboost**: Construccion de modelos de manera secuencial para generar modelos de alto rendimiento.\n",
        "- **shap**: Biblioteca para mostrar los resultados de los modelos de ML e interpretación de modelos complejos\n",
        "\n",
        "## Instalación\n",
        "### Prerrequisitos\n",
        " Asegurarse de tener instalado:\n",
        " - Python 3.11 el cual es la version actualmente mas estable\n",
        " - Poetry (Para gestionar dependencias y versionamiento)\n",
        "\n",
        "### Pasos de instalación\n",
        "1. Se recomienda la creación de un entorno nuevo para el despliegue del proyecto:\n",
        "```bash\n",
        "conda create -n ml_ean_2024\n",
        "```\n",
        "2. Activamos el entorno\n",
        "```bash\n",
        "conda activate ml_ean_2024\n",
        "```\n",
        "3. Si ya tienes instalado la aplicación Git, se debe clonar el repositorio en la carpeta que hayas creado:\n",
        "```bash\n",
        "git clone https://github.com/josedavinchi/ml_ean_2024_proyectofinal.git\n",
        "```\n",
        "\n",
        "4. Debido a que estamos en un entorno nuevo, debemos instalar el ipykernel(Kernel de python) y el poetry\n",
        "```bash\n",
        "pip install ipykernel poetry\n",
        "```\n",
        "### Despliegue del proyecto\n",
        "Dirigirse a la carpeta donde se tiene el proyecto clonado y ejecutar lo siguiente:\n",
        "```bash\n",
        "poetry install\n",
        "```\n",
        "En caso de que la versión de python del entorno sea diferente al del proyecto ejecutar lo siguiente para solucionar las dependencias:\n",
        "```bash\n",
        "poetry lock\n",
        "```\n",
        "## Integrantes\n",
        "- Báez Bermúdez, Cristian David (Estudiante de la especialización en machine learning)\n",
        "- Rodriguez  Simmonds, Santiago (Estudiante de la especialización en machine learning)\n",
        "- Rodríguez Díaz, Germán Alonso (Estudiante de la especialización en machine learning)\n",
        "- Mariño Florez,  David José (Estudiante de la especialización en machine learning)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MIHddQc9VpKz"
      }
    }
  ]
}